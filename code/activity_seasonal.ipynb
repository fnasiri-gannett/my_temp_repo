{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../data/us_CID_activity_2014_2017.csv') # Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head() # Take a quick look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(887709, 52)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape # Check out the size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.columns # Check out the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['USA', nan], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Country.unique() # Given that this is the US data, the NaNs are USA as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['USD', nan], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Currency.unique() # Given that this is the US data, the NaNs are USD as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Partner', 'DirectLocal', 'National', 'Deals', nan], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Channel.unique() # Need to figure out what to do with NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Country', 'Currency', 'Advertiser_URL'], axis=1, inplace=True) # Useless data in this context\n",
    "df.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df.dtypes # Check the data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Radius', 'Country', 'Metro', 'City', 'PostCode'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.TargetType.unique() # What's this column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.describe().T # Let's get a feel for the data --> There are campaign budgets equal to zero!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the \"unnecessary\" columns (for now)\n",
    "\n",
    "df.drop(columns=['BC_ID','BusinessCategory', 'Primary_BSC_ID', 'Primary_BusinessSubCategory',\n",
    "                'Secondary_BSC_Count','Secondary_BSC_IDs','Seconardy_BSCs','BusinessSpecialtyID',\n",
    "                'BusinessSpecialty'], axis=1, inplace=True)\n",
    "df.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's look at the fishy stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18545"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CPL an CTL have exactly the same number of missing values. Check and see if this is because of the \n",
    "# product type.\n",
    "\n",
    "# Check to see if they're are missing at the exact same locations:\n",
    "\n",
    "print( (((np.isnan(df.CTL)) & (np.isnan(df.CPL))).sum()) == df.CTL.isna().sum() )\n",
    "\n",
    "temp=df[['idadvertiser_master', 'idOffer', 'Offer_Name','CPL', 'CTL']]\n",
    "\n",
    "temp[np.isnan(temp.CTL)]['idadvertiser_master'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38042"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.idadvertiser_master.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quite a lot of the data is missing from CPL and CLT. For about half of the \n",
    "# advertisers, this data is missing. Check what they are. For the time \n",
    "# being let's drop them. Same thing with CPC and CTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['CTL', 'CPL','CPC', 'CTR'], axis=1, inplace=True)\n",
    "df.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with Offer, Finance Product, idOffer (There are only a few of them?)\n",
    "\n",
    "missing_offer_ids=df[df.Offer_Name.isna()]['idadvertiser_master'].unique()\n",
    "\n",
    "# Check to see if their are missing at the exact same locations:\n",
    "\n",
    "df=df[~df.idadvertiser_master.isin(missing_offer_ids)]\n",
    "df.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a duration column. For missing values, one option is to replace with the average \n",
    "# campaign duration of a given advertiser--> Local!\n",
    "# However we're not sure why the cycle is missing an end date. Is that churn?\n",
    "df['Cycle_Started']=pd.to_datetime(df.Cycle_Started, format='%Y-%m-%d',  errors='ignore')\n",
    "df['Cycle_Ended']=pd.to_datetime(df.Cycle_Ended, format='%Y-%m-%d',  errors='ignore')\n",
    "\n",
    "my_index=df[df['Cycle_Ended'] < df['Cycle_Started']].index\n",
    "\n",
    "temp=df.loc[my_index, 'Cycle_Ended']\n",
    "\n",
    "df.loc[my_index, 'Cycle_Ended'] = df.loc[my_index, 'Cycle_Started']\n",
    "\n",
    "df.loc[my_index, 'Cycle_Started']=temp\n",
    "\n",
    "\n",
    "df.reset_index(inplace=True,drop=True)\n",
    "df['cycle_duration']=pd.to_timedelta(df['Cycle_Ended']-df['Cycle_Started']).astype('timedelta64[D]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[np.isnan(df.cycle_duration)][['idadvertiser', 'campaign_budget','Cycle_Started', 'Cycle_Ended','cycle_duration']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are campaigns for which duration is NaN but it's because the campaign started on 2017-12-31 and that's the cut off for the dataset. Let's drop those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of the campaigns with zero budget and those starting at the end of the year.\n",
    "df=df[~(df.campaign_budget==0)]\n",
    "df=df[~(df.campaign_budget < 1)]\n",
    "\n",
    "df=df[~(df.Cycle_Started==pd.to_datetime('2017-12-31 00:00:00'))]\n",
    "\n",
    "df.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[pd.isnull(df.Cycle_Started)]['idadvertiser_master'].nunique() # Two master_adv_ids don't have a start date. Drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids=df[pd.isnull(df.Cycle_Started)]['idadvertiser_master'].unique()\n",
    "\n",
    "df=df[~(df.idadvertiser_master.isin(ids))]\n",
    "\n",
    "df.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.265992167101828"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[pd.isnull(df.Cycle_Ended)]['idadvertiser_master'].nunique()/df.idadvertiser_master.nunique()*100\n",
    "\n",
    "# 15% of the master_adv_ids have campaigns in them. Too much of the data. We need to impute this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_mode=df.cycle_duration.mode() # Mode is 30. Let's impute the duration with this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_index=df[pd.isnull(df.cycle_duration)].index\n",
    "#df.loc[my_index, 'cycle_duration']=duration_mode\n",
    "\n",
    "df['cycle_duration'].fillna(duration_mode[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now reconstruct the end dates\n",
    "my_index=df[pd.isnull(df.Cycle_Ended)].index\n",
    "df.loc[my_index, 'Cycle_Ended']=df.loc[my_index, 'Cycle_Started']+pd.to_timedelta(str(duration_mode[0])+'D')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FNasiri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\FNasiri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\FNasiri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\FNasiri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\FNasiri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:935: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._set_with(key, value)\n",
      "C:\\Users\\FNasiri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2961: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Users\\FNasiri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\FNasiri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\FNasiri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\FNasiri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\mkl_fft\\_numpy_fft.py:158: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  output = mkl_fft.fft(a, n, axis)\n",
      "C:\\Users\\FNasiri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\FNasiri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Users\\FNasiri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Users\\FNasiri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1738: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  cond2 = (x >= self.b) & cond0\n",
      "C:\\Users\\FNasiri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:28: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims, initial)\n",
      "C:\\Users\\FNasiri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:83: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "C:\\Users\\FNasiri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    }
   ],
   "source": [
    "# Sort my master_adv_id and cycle start date then reset the main index.\n",
    "# It's possible to do this with adv_id\n",
    "#df.sort_values(by=['idadvertiser_master','Cycle_Started'])\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "# Trim down the dataframe\n",
    "temp=df[['idadvertiser_master','idadvertiser','Cycle_Started','Cycle_Ended','cycle_duration']]\n",
    "# Find unique ids \n",
    "adv_ids=temp.idadvertiser_master.unique()\n",
    "\n",
    "# Create additional columns\n",
    "temp['delta']=0.0\n",
    "temp['summation']=0.0\n",
    "\n",
    "import scipy.stats as sts\n",
    "\n",
    "seasonal=[]\n",
    "period=[]\n",
    "# Loop over ids\n",
    "for idd in adv_ids:\n",
    "    subset = temp[temp.idadvertiser_master==idd]\n",
    "    subset.sort_values(by=['idadvertiser_master','Cycle_Started'],inplace=True)\n",
    "    subset.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    if subset.shape[0]<2:\n",
    "        seasonal.append(0)\n",
    "        period.append(0)\n",
    "    else:\n",
    "    \n",
    "        # Separating start and end\n",
    "        start = subset.Cycle_Started\n",
    "        end = subset.Cycle_Ended\n",
    "\n",
    "        end_shift = end\n",
    "        end_shift[1:]=end[0:-1]\n",
    "\n",
    "        delta = start-end_shift\n",
    "        subset['delta']=0.0\n",
    "        for i in range(0,subset.shape[0]):\n",
    "            subset.loc[i,'delta']=delta.iloc[i].days\n",
    "\n",
    "        subset.loc[0,'delta']=0\n",
    "\n",
    "        #subset['delta']=delta\n",
    "        subset['summation']=subset['cycle_duration']+subset['delta']\n",
    "\n",
    "        # Create the time series\n",
    "\n",
    "        time_series= np.ones((1,int(subset['summation'].sum())))\n",
    "        pivot = 0\n",
    "        for i in range(0,subset.shape[0]):\n",
    "            if subset.loc[i,'delta'] > 0:\n",
    "                start_index=int(subset.loc[0:i,'summation'].sum() )\n",
    "                end_index=start_index+int( subset.loc[i,'delta'] )\n",
    "                time_series[0][start_index:end_index]=0\n",
    "                pivot=i\n",
    "\n",
    "        # Next largest power of 2        \n",
    "        nfft=1<<(time_series.shape[1]-1).bit_length()\n",
    "\n",
    "        y=np.fft.fft(time_series, n=nfft)\n",
    "        y=abs(y**2)\n",
    "        y=(y-y.min())\n",
    "        y=y/y.max()\n",
    "\n",
    "        s, p  = sts.kstest(y, 'uniform')\n",
    "\n",
    "        if (p < 0.05) and (np.argmax(y)/nfft != 0): # the second argument is the frequency. \n",
    "            seasonal.append(1)\n",
    "            period.append(1/np.argmax(y)/nfft)\n",
    "        else:\n",
    "            seasonal.append(0)\n",
    "            period.append(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/seasonal.txt', 'w') as f:\n",
    "    for item in seasonal:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/periods.txt', 'w') as f:\n",
    "    for item in period:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
